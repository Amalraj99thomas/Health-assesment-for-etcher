
%% This code tested on MATLAB R2021b, 2022.03.30


%% 0: Clean up
clear all;
clc;
close all;


%% 1: Set file path
dir_home     = 'C:\Users\minamitu\OneDrive - University of Cincinnati\_CLASS\2-1_IndustrialAI\Final\_Shared';
toolbox      = '.\somtoolbox';

%% 2: Read training data

% set dir
cd(dir_home)

% load mat file(train and test)
load("train/Baseline1DataSet.mat")
load("train/Baseline2DataSet.mat")
load("train/Baseline3DataSet.mat")

load("test/TestCase1DataSet.mat")
load("test/TestCase2DataSet.mat")
load("test/TestCase3DataSet.mat")

% joint all data
data_train = [Baseline1Run;Baseline2Run;Baseline3Run];
data_test  = [TestCase1Run;TestCase2Run;TestCase3Run];

% set parameters
N_train = 75; % 25+25+25 runs (from data)
N_test  = 48; % 18+15+15 runs (from data)

Fs = 1000;                      % Sampling frequency (from instruction)
Ts = 1/Fs;                      % Sampling period
L = 106;                        % Length of signal (from data)
t = (0:L-1)*Ts;                 % Time vector

% Visualize one data from Baseline1
train = data_train{1,1}.Data;
figure;
for ii = 2:21
    subplot(4,5,ii-1)
    plot(t, train(:,ii),'b')
    %xlabel('Time (s)')
    xlim([0.0 0.11])
    %ylabel('Amplitude')
    %ylim([-0.5 0.5])
    title(ii)
end

%% X: Pre-processing

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To Be Done

% We should check raw sensor data
% then eliminate abnormal data and missing data etc. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% 3: Feature extraction of training data

N_feat = 10*19;        % Number of features

FeatMat_train = zeros(N_train, N_feat); % Feature Matrix of training data

N = N_train;
for ii = 1:N
    data_all = data_train{ii,1}.Data; % SETTING
    
    for jj = 1:19 % Use 19 sensors data

        row = find(data_all(:,2)==4);
        data_i1 = data_all(row,jj+2); % Use #3 to #21 from data
        
        row = find(data_all(:,2)==5);
        data_i2 = data_all(row,jj+2); % Use #3 to #21 from data

        FeatMat_train(ii,10*(jj-1)+1) = mean(data_i1);       % feature 1: Mean
        FeatMat_train(ii,10*(jj-1)+2) = std(data_i1);        % feature 2: STD
        FeatMat_train(ii,10*(jj-1)+3) = min(data_i1);        % feature 3: Minimum
        FeatMat_train(ii,10*(jj-1)+4) = max(data_i1);        % feature 4: Maximum 
        FeatMat_train(ii,10*(jj-1)+5) = kurtosis(data_i1);   % feature 5: Kurtosis

        FeatMat_train(ii,10*(jj-1)+6) = mean(data_i2);       % feature 1: Mean
        FeatMat_train(ii,10*(jj-1)+7) = std(data_i2);        % feature 2: STD
        FeatMat_train(ii,10*(jj-1)+8) = min(data_i2);        % feature 3: Minimum
        FeatMat_train(ii,10*(jj-1)+9) = max(data_i2);        % feature 4: Maximum 
        FeatMat_train(ii,10*(jj-1)+10)= kurtosis(data_i2);   % feature 5: Kurtosis

    end
end

% NaN ga fukumareru idx ha?


FeatMat_train(isnan(FeatMat_train))=0; % Replace NaN with 0

S1 = sum(FeatMat_train);
S2 = max(FeatMat_train);
S3 = min(FeatMat_train);

FeatMat_train(1:find(max(FeatMat_train)==0 & min(FeatMat_train)==0));

idx = max(FeatMat_train)==0 & min(FeatMat_train)==0;
xxx = find(max(FeatMat_train)==0 & min(FeatMat_train)==0)

C1 = cat(1,S2,S3,idx);


%% X: Normalizing(TRAINING data)

% To be done (probably)

FeatMat_mean = zeros(N_feat);                   % Mean of each features
FeatMat_std = zeros(N_feat);                    % STD of each feature
FeatMat_train_norm = zeros(N_train, N_feat);    % Normalized data (training)

for ii = 1:N_feat

    FeatMat_mean(ii) = mean(FeatMat_train(:,ii));   % Calc. mean
    FeatMat_std(ii) = std(FeatMat_train(:,ii));     % Calc. std

    % Normalizing
    FeatMat_train_norm(:,ii) = ...
        (FeatMat_train(:,ii) - FeatMat_mean(ii))/FeatMat_std(ii);

end

%% 4: Dimension Reduction(PCA)

%共分散の計算
sigma = cov(FeatMat_train);

%固有値計算
[vec val] = eig(sigma);

%固有値が最も大きな固有ベクトルを変換行列にする
[r	c] = find(val == max(val(:)));
w = vec(:,c);

%各座標を変換
x = zeros(N,1);
for i = 1:N
	x(i,1) = FeatMat_train(i,:) * w;
end

%変換後のデータを表示。yの値は 0 とする
figure(3)
clf
plot(x(:,1),0,"bo");
% xlim([-5,5]);
% ylim([-5,5]);
%print -deps fig_out2.eps

print("X")

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To Be done
% Challenging part
 
[coeff,scoreTrain,latent,tsquared,explained,mu] = pca(FeatMat_train); % Find the principal components for the training data 

explained % Display the percent variability

idx = find(cumsum(explained)>95,1) %  Find the number of components required to explain at least 95% variability.

scoreTrain95 = scoreTrain(:,1:idx);

mdl = fitctree(scoreTrain95,YTrain); % Train a classification tree using the first two components.

scoreTest95 = (XTest-mu)*coeff(:,1:idx); % To use the trained model for the test set, you need to transform the test data set by using the PCA obtained from the training data set. Obtain the principal component scores of the test data set by subtracting mu from XTest and multiplying by coeff. Only the scores for the first two components are necessary, so use the first two coefficients coeff(:,1:idx).

YTest_predicted = predict(mdl,scoreTest95); %Pass the trained model mdl and the transformed test data set scoreTest to the predict function to predict ratings for the test set.

% T2 
tsqreduced = mahal(score,score)

% PLOT

scatter3(score(:,1),score(:,2),score(:,3))
axis equal
xlabel('1st Principal Component')
ylabel('2nd Principal Component')
zlabel('3rd Principal Component')

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%% X: Feature extraction(TEST data) 

FeatMat_test = zeros(N_test, N_feat);
N = N_test;

for ii = 1:N
    data_all = data_test{ii,1}.Data; % SETTING
    
    for jj = 1:19 % Use #3 to #21 from data

        row = find(data_all(:,2)==4);
        data_i1 = data_all(row,jj+2); % Use #3 to #21 from data
        
        row = find(data_all(:,2)==5);
        data_i2 = data_all(row,jj+2); % Use #3 to #21 from data

        FeatMat_test(ii,10*(jj-1)+1) = mean(data_i1);       % feature 1: Mean
        FeatMat_test(ii,10*(jj-1)+2) = std(data_i1);        % feature 2: STD
        FeatMat_test(ii,10*(jj-1)+3) = min(data_i1);        % feature 3: Minimum
        FeatMat_test(ii,10*(jj-1)+4) = max(data_i1);        % feature 4: Maximum 
        FeatMat_test(ii,10*(jj-1)+5) = kurtosis(data_i1);   % feature 5: Kurtosis

        FeatMat_test(ii,10*(jj-1)+6) = mean(data_i2);       % feature 1: Mean
        FeatMat_test(ii,10*(jj-1)+7) = std(data_i2);        % feature 2: STD
        FeatMat_test(ii,10*(jj-1)+8) = min(data_i2);        % feature 3: Minimum
        FeatMat_test(ii,10*(jj-1)+9) = max(data_i2);        % feature 4: Maximum 
        FeatMat_test(ii,10*(jj-1)+10)= kurtosis(data_i2);   % feature 5: Kurtosis
    end
end


%% XX: Normalizing(TEST data) 

% To be done (probably)

% FeatMat_test_norm = zeros(N_test, N_feat);
% 
% for ii = 1:N_feat
% 
%     % Normalizing (using mean and std of training data)
%     FeatMat_test_norm(:,ii) = ...
%         (FeatMat_test(:,ii) - FeatMat_mean(ii))/FeatMat_std(ii);
% 
% end


%% XX: temp.

FeatMat_train_norm = FeatMat_train;
FeatMat_test_norm  = FeatMat_test;

%% A. SOM-MQE

cd(toolbox)
% clc;


% A1. Training 
sD_1 = som_data_struct(FeatMat_train_norm);
sM_1 = som_make(sD_1);


% A2. MQE
for k = 1:size(FeatMat_train_norm, 1)
    qe = som_quality(sM_1,FeatMat_train_norm(k,:));
    MQE_train_1(k,1) = qe;
end

for k = 1:size(FeatMat_test_norm, 1)
    qe = som_quality(sM_1,FeatMat_test_norm(k,:));
    MQE_test_1(k,1) = qe;
end

MQE_max_1 = max(MQE_train_1);
MQE_train_n1 = 1-MQE_train_1/MQE_max_1;
MQE_test_n1  = 1-MQE_test_1/MQE_max_1;

% A3. plot
figure;
plot(MQE_train_1(:,1),"--o");
title("MQE:train");

figure;
plot(MQE_test_1(:,1),":*r");
title("MQE:test");

figure;
plot(MQE_train_n1(:,1),"--o");
title("CV:train");

figure;
plot(MQE_test_n1(:,1),":*r");
title("CV:test");

%% Output prediction

% To Be Done

%% Test something



